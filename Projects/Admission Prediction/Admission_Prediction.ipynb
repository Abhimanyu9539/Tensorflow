{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf68ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b0b264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
       "0             1      337.0        118.0                4.0  4.5  4.5  9.65   \n",
       "1             2      324.0        107.0                4.0  4.0  4.5  8.87   \n",
       "2             3        NaN        104.0                3.0  3.0  3.5  8.00   \n",
       "3             4      322.0        110.0                3.0  3.5  2.5  8.67   \n",
       "4             5      314.0        103.0                2.0  2.0  3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...  ...   ...   \n",
       "495         496      332.0        108.0                5.0  4.5  4.0  9.02   \n",
       "496         497      337.0        117.0                5.0  5.0  5.0  9.87   \n",
       "497         498      330.0        120.0                5.0  4.5  5.0  9.56   \n",
       "498         499      312.0        103.0                4.0  4.0  5.0  8.43   \n",
       "499         500      327.0        113.0                4.0  4.5  4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit  \n",
       "0           1             0.92  \n",
       "1           1             0.76  \n",
       "2           1             0.72  \n",
       "3           1             0.80  \n",
       "4           0             0.65  \n",
       "..        ...              ...  \n",
       "495         1             0.87  \n",
       "496         1             0.96  \n",
       "497         1             0.93  \n",
       "498         0             0.73  \n",
       "499         0             0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"Admission_Prediction.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f415d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 485 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          485 non-null    float64\n",
      " 1   TOEFL Score        485 non-null    float64\n",
      " 2   University Rating  485 non-null    float64\n",
      " 3   SOP                485 non-null    float64\n",
      " 4   LOR                485 non-null    float64\n",
      " 5   CGPA               485 non-null    float64\n",
      " 6   Research           485 non-null    int64  \n",
      " 7   Chance of Admit    485 non-null    float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 34.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Serial No.'], axis=1, inplace=True)\n",
    "df['GRE Score'].fillna(df['GRE Score'].mean(), inplace=True)\n",
    "df['TOEFL Score'].fillna(df['TOEFL Score'].mean(), inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b2e788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    273\n",
       "0    212\n",
       "Name: Research, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Research'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9dee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(485, 7)\n",
      "(485,)\n"
     ]
    }
   ],
   "source": [
    "Y=df['Research']\n",
    "X=df.drop(['Research'], axis=1)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c90c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e606406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                256       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,593\n",
      "Trainable params: 6,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "\n",
    "model.add(keras.Input(shape=X.shape[1]))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "116f75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4987cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "39/39 [==============================] - 3s 9ms/step - loss: 3.2957 - accuracy: 0.5155 - val_loss: 1.5888 - val_accuracy: 0.3814\n",
      "Epoch 2/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.9392 - accuracy: 0.4923 - val_loss: 0.8858 - val_accuracy: 0.3814\n",
      "Epoch 3/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.5103 - val_loss: 0.8645 - val_accuracy: 0.6186\n",
      "Epoch 4/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.8944 - accuracy: 0.5103 - val_loss: 0.6374 - val_accuracy: 0.5876\n",
      "Epoch 5/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.8081 - accuracy: 0.5052 - val_loss: 0.7082 - val_accuracy: 0.5464\n",
      "Epoch 6/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8451 - accuracy: 0.4923 - val_loss: 1.3590 - val_accuracy: 0.3814\n",
      "Epoch 7/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.9872 - accuracy: 0.5052 - val_loss: 1.0217 - val_accuracy: 0.6186\n",
      "Epoch 8/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.8094 - accuracy: 0.5206 - val_loss: 0.6867 - val_accuracy: 0.5670\n",
      "Epoch 9/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8134 - accuracy: 0.5515 - val_loss: 0.7386 - val_accuracy: 0.6186\n",
      "Epoch 10/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7820 - accuracy: 0.5773 - val_loss: 0.6505 - val_accuracy: 0.5979\n",
      "Epoch 11/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8162 - accuracy: 0.5361 - val_loss: 0.6329 - val_accuracy: 0.6289\n",
      "Epoch 12/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8912 - accuracy: 0.5309 - val_loss: 1.6216 - val_accuracy: 0.3814\n",
      "Epoch 13/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.5670 - val_loss: 0.7282 - val_accuracy: 0.5567\n",
      "Epoch 14/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8067 - accuracy: 0.5541 - val_loss: 0.6149 - val_accuracy: 0.6289\n",
      "Epoch 15/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.6057 - val_loss: 0.6861 - val_accuracy: 0.6289\n",
      "Epoch 16/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7509 - accuracy: 0.5876 - val_loss: 0.6061 - val_accuracy: 0.6289\n",
      "Epoch 17/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7568 - accuracy: 0.5747 - val_loss: 0.6049 - val_accuracy: 0.6186\n",
      "Epoch 18/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.6005 - val_loss: 0.6218 - val_accuracy: 0.6289\n",
      "Epoch 19/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.6340 - val_loss: 0.6365 - val_accuracy: 0.6186\n",
      "Epoch 20/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8003 - accuracy: 0.5490 - val_loss: 0.6046 - val_accuracy: 0.6186\n",
      "Epoch 21/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1.0043 - accuracy: 0.5490 - val_loss: 0.7574 - val_accuracy: 0.5258\n",
      "Epoch 22/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6418 - val_loss: 0.6014 - val_accuracy: 0.6289\n",
      "Epoch 23/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.5773 - val_loss: 0.6450 - val_accuracy: 0.6082\n",
      "Epoch 24/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7727 - accuracy: 0.6134 - val_loss: 0.8628 - val_accuracy: 0.4536\n",
      "Epoch 25/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.8559 - accuracy: 0.5284 - val_loss: 0.9757 - val_accuracy: 0.3918\n",
      "Epoch 26/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.6289 - val_loss: 0.6973 - val_accuracy: 0.6289\n",
      "Epoch 27/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7024 - accuracy: 0.5979 - val_loss: 0.9583 - val_accuracy: 0.3918\n",
      "Epoch 28/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.5722 - val_loss: 0.6539 - val_accuracy: 0.5979\n",
      "Epoch 29/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6469 - val_loss: 0.7276 - val_accuracy: 0.5464\n",
      "Epoch 30/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6572 - val_loss: 0.5950 - val_accuracy: 0.6701\n",
      "Epoch 31/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7283 - accuracy: 0.6005 - val_loss: 1.4113 - val_accuracy: 0.6186\n",
      "Epoch 32/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1.0651 - accuracy: 0.5361 - val_loss: 0.9076 - val_accuracy: 0.4330\n",
      "Epoch 33/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7726 - accuracy: 0.5747 - val_loss: 0.5971 - val_accuracy: 0.6701\n",
      "Epoch 34/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.6778 - val_loss: 0.6356 - val_accuracy: 0.6392\n",
      "Epoch 35/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.6160 - val_loss: 0.9155 - val_accuracy: 0.4433\n",
      "Epoch 36/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6418 - val_loss: 0.6487 - val_accuracy: 0.6186\n",
      "Epoch 37/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.5567 - val_loss: 0.8693 - val_accuracy: 0.6186\n",
      "Epoch 38/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7444 - accuracy: 0.6031 - val_loss: 0.5962 - val_accuracy: 0.6804\n",
      "Epoch 39/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6933 - val_loss: 0.5959 - val_accuracy: 0.6804\n",
      "Epoch 40/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6521 - val_loss: 0.5942 - val_accuracy: 0.6495\n",
      "Epoch 41/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.6005 - val_loss: 0.6320 - val_accuracy: 0.6289\n",
      "Epoch 42/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7016 - accuracy: 0.5722 - val_loss: 0.6614 - val_accuracy: 0.6289\n",
      "Epoch 43/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.6495 - val_loss: 0.6042 - val_accuracy: 0.6804\n",
      "Epoch 44/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.6598 - val_loss: 0.6231 - val_accuracy: 0.6289\n",
      "Epoch 45/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.6443 - val_loss: 0.5943 - val_accuracy: 0.6701\n",
      "Epoch 46/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7104 - accuracy: 0.6366 - val_loss: 0.9568 - val_accuracy: 0.4330\n",
      "Epoch 47/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7183 - accuracy: 0.6263 - val_loss: 0.5998 - val_accuracy: 0.6804\n",
      "Epoch 48/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6546 - val_loss: 0.6345 - val_accuracy: 0.6186\n",
      "Epoch 49/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6418 - val_loss: 0.5994 - val_accuracy: 0.6289\n",
      "Epoch 50/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.6237 - val_loss: 0.5951 - val_accuracy: 0.6392\n",
      "Epoch 51/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6237 - val_loss: 0.6692 - val_accuracy: 0.6186\n",
      "Epoch 52/80\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.6546 - val_loss: 0.5908 - val_accuracy: 0.7113\n",
      "Epoch 53/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6572 - val_loss: 0.5971 - val_accuracy: 0.6289\n",
      "Epoch 54/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.6392 - val_loss: 0.7249 - val_accuracy: 0.5773\n",
      "Epoch 55/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.6263 - val_loss: 0.7338 - val_accuracy: 0.6186\n",
      "Epoch 56/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6314 - val_loss: 0.5944 - val_accuracy: 0.6907\n",
      "Epoch 57/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6649 - val_loss: 0.6600 - val_accuracy: 0.6392\n",
      "Epoch 58/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6727 - val_loss: 0.6186 - val_accuracy: 0.6598\n",
      "Epoch 59/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.6546 - val_loss: 0.8585 - val_accuracy: 0.4742\n",
      "Epoch 60/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6418 - val_loss: 0.5940 - val_accuracy: 0.6598\n",
      "Epoch 61/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6495 - val_loss: 0.6658 - val_accuracy: 0.6082\n",
      "Epoch 62/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6624 - val_loss: 0.7162 - val_accuracy: 0.5773\n",
      "Epoch 63/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6804 - val_loss: 0.7515 - val_accuracy: 0.5361\n",
      "Epoch 64/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.5928 - val_loss: 0.6466 - val_accuracy: 0.6289\n",
      "Epoch 65/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.6675 - val_loss: 0.5901 - val_accuracy: 0.6907\n",
      "Epoch 66/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6727 - val_loss: 0.5927 - val_accuracy: 0.6495\n",
      "Epoch 67/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6108 - val_loss: 0.6167 - val_accuracy: 0.6392\n",
      "Epoch 68/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6804 - val_loss: 0.6487 - val_accuracy: 0.6598\n",
      "Epoch 69/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6469 - val_loss: 0.6150 - val_accuracy: 0.6289\n",
      "Epoch 70/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6521 - val_loss: 0.5916 - val_accuracy: 0.6495\n",
      "Epoch 71/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6727 - val_loss: 0.7979 - val_accuracy: 0.5258\n",
      "Epoch 72/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.6289 - val_loss: 0.8650 - val_accuracy: 0.6186\n",
      "Epoch 73/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7376 - accuracy: 0.5825 - val_loss: 0.6132 - val_accuracy: 0.6495\n",
      "Epoch 74/80\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.6521 - val_loss: 0.6118 - val_accuracy: 0.6495\n",
      "Epoch 75/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.6753 - val_loss: 0.7374 - val_accuracy: 0.5567\n",
      "Epoch 76/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.6804 - val_loss: 0.5908 - val_accuracy: 0.6804\n",
      "Epoch 77/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6418 - val_loss: 0.6105 - val_accuracy: 0.6495\n",
      "Epoch 78/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.6366 - val_loss: 0.6139 - val_accuracy: 0.6495\n",
      "Epoch 79/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.6778 - val_loss: 0.6112 - val_accuracy: 0.6495\n",
      "Epoch 80/80\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.6830 - val_loss: 0.6345 - val_accuracy: 0.6495\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,\n",
    "                    Y,\n",
    "                    epochs=80, # you can set this to a big number!\n",
    "                    batch_size=10, ## Create model for 10 point and update parameters\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873fa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
